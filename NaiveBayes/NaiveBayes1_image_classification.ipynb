{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000, 5000, 980, 1135]\n",
      "Your trainset and testset are generated successfully!\n",
      "44.2146428571 115.550258903 87.43059533674777 101.4688032971233 19.4110196429 32.7003438061 61.386556126668715 84.8037115156687\n",
      "training accuracy 0.9237\n",
      "class 0 accuracy 0.9163265306122449\n",
      "class 1 acccuracy 0.9233480176211454\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import scipy.io\n",
    "import math\n",
    "import geneNewData\n",
    "\n",
    "def get_mean(sample_image):\n",
    "    flattened_sample_image=sample_image.flatten()\n",
    "    return sum(flattened_sample_image)/len(flattened_sample_image)\n",
    "def get_std(sample_image):\n",
    "    mean=get_mean(sample_image)\n",
    "    flattened_sample_image=sample_image.flatten()    \n",
    "    return math.sqrt(sum((flattened_sample_image-mean)**2)/len(flattened_sample_image) )\n",
    "\n",
    "#since we have assumed that these two features are independent, and that each image is drawn from a normal distribution. \n",
    "def likelihood_fun(x, mean,var):\n",
    "    return (1/math.sqrt(2*math.pi*var) )*math.exp((-(x-mean)**2)/(2*var))\n",
    "\n",
    "def posterior_prob(params,example):\n",
    "    #class_prob_0=0.5\n",
    "    #class_prob_1=0.5\n",
    "    posterior_0= math.log(likelihood_fun( example[0],params[0][0],params[0][1]) )+ math.log(likelihood_fun( example[1],params[0][2],params[0][3])) #+math.log(.5)\n",
    "    posterior_1= math.log(likelihood_fun( example[0],params[1][0],params[1][1]) )+ math.log(likelihood_fun( example[1],params[1][2],params[1][3])) #+math.log(.5)\n",
    "    predict= 0 if posterior_0 > posterior_1 else 1\n",
    "    return predict\n",
    "\n",
    "def main():\n",
    "    myID='4427'\n",
    "    geneNewData.geneData(myID)\n",
    "    Numpyfile0 = scipy.io.loadmat('digit0_stu_train'+myID+'.mat')\n",
    "    Numpyfile1 = scipy.io.loadmat('digit1_stu_train'+myID+'.mat')\n",
    "    Numpyfile2 = scipy.io.loadmat('digit0_testset'+'.mat')\n",
    "    Numpyfile3 = scipy.io.loadmat('digit1_testset'+'.mat')\n",
    "    train0 = Numpyfile0.get('target_img')\n",
    "    train1 = Numpyfile1.get('target_img')\n",
    "    test0 = Numpyfile2.get('target_img')\n",
    "    test1 = Numpyfile3.get('target_img')\n",
    "    print([len(train0),len(train1),len(test0),len(test1)])\n",
    "    print('Your trainset and testset are generated successfully!')\n",
    "    #    pass\n",
    "    #--------task 1\n",
    "    #avg_brightness_0=[numpy.mean(image) for image in train0] \n",
    "    avg_brightness_0= list(map(get_mean,train0))\n",
    "    #std_brightness_0=[numpy.std(image) for image in train0] \n",
    "    std_brightness_0= list(map(get_std,train0))\n",
    "    #avg_brightness_1=[numpy.mean(image) for image in train1] \n",
    "    avg_brightness_1=list(map(get_mean,train1))\n",
    "    #std_brightness_1=[numpy.std(image) for image in train1] \n",
    "    std_brightness_1= list(map(get_std,train1))\n",
    "\n",
    "    #-------task 2\n",
    "    #mean_avg_brightness_0=numpy.mean(avg_brightness_0)\n",
    "    mean_avg_brightness_0=sum(avg_brightness_0)/len(avg_brightness_0)\n",
    "    #var_avg_brightness_0=numpy.var(avg_brightness_0)\n",
    "    var_avg_brightness_0= sum((x-mean_avg_brightness_0)**2 for x in avg_brightness_0)/len(avg_brightness_0)\n",
    "    #mean_std_brightness_0=numpy.mean(std_brightness_0)\n",
    "    mean_std_brightness_0=sum(std_brightness_0)/len(std_brightness_0)\n",
    "    #var_std_brightness_0= numpy.var(std_brightness_0)\n",
    "    var_std_brightness_0=sum((x-mean_std_brightness_0)**2 for x in std_brightness_0)/len(std_brightness_0)\n",
    "\n",
    "    #mean_avg_brightness_1=numpy.mean(avg_brightness_1)\n",
    "    mean_avg_brightness_1=sum(avg_brightness_1)/len(avg_brightness_1)\n",
    "    #var_avg_brightness_1=numpy.var(avg_brightness_1)\n",
    "    var_avg_brightness_1= sum((x-mean_avg_brightness_1)**2 for x in avg_brightness_1)/len(avg_brightness_1)\n",
    "    #mean_std_brightness_1=numpy.mean(std_brightness_1)\n",
    "    mean_std_brightness_1=sum(std_brightness_1)/len(std_brightness_1)\n",
    "    #var_std_brightness_1= numpy.var(std_brightness_1)\n",
    "    var_std_brightness_1=sum((x-mean_std_brightness_1)**2 for x in std_brightness_1)/len(std_brightness_1)\n",
    "\n",
    "    print(mean_avg_brightness_0,var_avg_brightness_0,\n",
    "          mean_std_brightness_0,var_std_brightness_0,\n",
    "          mean_avg_brightness_1,var_avg_brightness_1\n",
    "         ,mean_std_brightness_1,var_std_brightness_1)\n",
    "\n",
    "    #----------task 3 and 4\n",
    "    data_train_0=[[avg_brightness_0[i],std_brightness_0[i]] for i in range(len(avg_brightness_0))]\n",
    "    data_train_1=[[avg_brightness_1[i],std_brightness_1[i]] for i in range(len(avg_brightness_1))]\n",
    "    params=[\n",
    "        [mean_avg_brightness_0,var_avg_brightness_0,mean_std_brightness_0,var_std_brightness_0],\n",
    "\n",
    "        [mean_avg_brightness_1,var_avg_brightness_1,mean_std_brightness_1,var_std_brightness_1]\n",
    "    ]\n",
    "    #training accuracry\n",
    "    pred_0=[]\n",
    "    pred_1=[]\n",
    "    for i,j in enumerate(data_train_0):\n",
    "        pred_0.append(posterior_prob(params,data_train_0[i]))\n",
    "        pred_1.append(posterior_prob(params,data_train_1[i]))\n",
    "    test_level=pred_0+pred_1\n",
    "    train_level_0=list(0 * numpy.ones(len(data_train_0)))\n",
    "    train_level_1=list(1* numpy.ones(len(data_train_1)))\n",
    "    train_level=train_level_0+train_level_1\n",
    "    accuracy= sum(1 for x,y in zip(train_level,test_level) if x==y)/len(train_level)\n",
    "    print(\"training accuracy\",accuracy)\n",
    "\n",
    "    #testing\n",
    "    '''\n",
    "    avg_brightness_0=[numpy.mean(image) for image in test0] \n",
    "    std_brightness_0=[numpy.std(image) for image in test0]\n",
    "    avg_brightness_1=[numpy.mean(image) for image in test1] \n",
    "    std_brightness_1=[numpy.std(image) for image in test1] \n",
    "    '''\n",
    "    avg_brightness_0= list(map(get_mean,test0))\n",
    "    std_brightness_0= list(map(get_std,test0))\n",
    "    avg_brightness_1= list(map(get_mean,test1))\n",
    "    std_brightness_1= list(map(get_std,test1))\n",
    "\n",
    "    data_test_0=[[avg_brightness_0[i],std_brightness_0[i]] for i in range(len(avg_brightness_0))]\n",
    "    data_test_1=[[avg_brightness_1[i],std_brightness_1[i]] for i in range(len(avg_brightness_1))]\n",
    "\n",
    "    test_pred_0=[]\n",
    "    test_pred_1=[]\n",
    "    for i,j in enumerate(data_test_0):\n",
    "        test_pred_0.append(posterior_prob(params,data_test_0[i]))\n",
    "    for i,j in enumerate(data_test_1):\n",
    "        test_pred_1.append(posterior_prob(params,data_test_1[i]))\n",
    "    test_pred=test_pred_0+test_pred_1\n",
    "    test_level_0=list(0 * numpy.ones(len(data_test_0)))\n",
    "    test_level_1=list(1* numpy.ones(len(data_test_1)))\n",
    "    Accuracy_for_digit0testset = sum(1 for x,y in zip(test_level_0,test_pred_0) if x==y)/len(test_level_0)\n",
    "    print(\"class 0 accuracy\",Accuracy_for_digit0testset)\n",
    "    Accuracy_for_digit1testset= sum(1 for x,y in zip(test_level_1,test_pred_1) if x==y)/len(test_level_1)\n",
    "    print(\"class 1 acccuracy\",Accuracy_for_digit1testset)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check1:\n",
    "# using mean and std from numpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 44.2146428571 115.550258903 87.4305953367 101.468803297 19.4110196429 32.7003438061 61.3865561267 84.8037115157\n",
    "#0.9163265306122449\n",
    "#0.9233480176211454"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check2:\n",
    "# verifying with  sklearn GaussianNB standard librarry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[data_train_0.append(item) for item in data_train_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9163265306122449\n",
      "0.9233480176211454\n"
     ]
    }
   ],
   "source": [
    "data=data_train_0\n",
    "train_level\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf2 = GaussianNB()\n",
    "clf2.class_prior_ = [0.5, 0.5]\n",
    "clf2.fit(numpy.array(data),numpy.array(train_level))\n",
    "re1=clf2.predict(numpy.array(data_test_0))\n",
    "res1=list(re1)\n",
    "Accuracy_for_digit0testset= sum(1 for x,y in zip(re1,test_level_0) if x==y)/len(test_level_0)\n",
    "print(Accuracy_for_digit0testset)\n",
    "re2=clf2.predict(numpy.array(data_test_1))\n",
    "res2=list(re2)\n",
    "Accuracy_for_digit1testset= sum(1 for x,y in zip(re2,test_level_1) if x==y)/len(test_level_1)\n",
    "print(Accuracy_for_digit1testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 115.55025917,  101.46880356],\n",
       "       [  32.70034407,   84.80371178]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.sigma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 44.21464286,  87.43059534],\n",
       "       [ 19.41101964,  61.38655613]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.theta_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
